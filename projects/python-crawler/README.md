# ğŸ•·ï¸ Pythonçˆ¬è™«æœåŠ¡

## é¡¹ç›®ç®€ä»‹
å½©ç¥¨æ•°æ®çˆ¬å–ã€åˆ†æå’Œé¢„æµ‹çš„PythonæœåŠ¡ï¼ŒåŸºäºFastAPIæ¡†æ¶æ„å»ºï¼Œæä¾›RESTful APIæ¥å£ã€‚

## ğŸš€ æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: FastAPI + Uvicorn
- **çˆ¬è™«**: Requests + BeautifulSoup4 + LXML
- **æ•°æ®åˆ†æ**: Pandas + NumPy + Scikit-learn
- **å¯è§†åŒ–**: Matplotlib + Seaborn + Plotly
- **æ•°æ®åº“**: PyMySQL + SQLAlchemy
- **ä»»åŠ¡è°ƒåº¦**: Schedule + APScheduler

## ğŸ“ é¡¹ç›®ç»“æ„
```
python-crawler/
â”œâ”€â”€ main.py              # FastAPIä¸»åº”ç”¨
â”œâ”€â”€ crawler.py           # çˆ¬è™«æ ¸å¿ƒé€»è¾‘
â”œâ”€â”€ database.py          # æ•°æ®åº“æ“ä½œ
â”œâ”€â”€ data_analysis.py     # æ•°æ®åˆ†ææ¨¡å—
â”œâ”€â”€ prediction_models.py # é¢„æµ‹æ¨¡å‹
â”œâ”€â”€ config.py            # é…ç½®æ–‡ä»¶
â”œâ”€â”€ config_docker.py     # Dockerç¯å¢ƒé…ç½®
â”œâ”€â”€ requirements.txt     # Pythonä¾èµ–
â”œâ”€â”€ Dockerfile          # Dockeré•œåƒæ„å»º
â”œâ”€â”€ logs/               # æ—¥å¿—ç›®å½•
â””â”€â”€ charts/             # å›¾è¡¨è¾“å‡ºç›®å½•
```

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.9+
- pip 20.0+
- MySQL 8.0+

### æœ¬åœ°å¼€å‘
```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd projects/python-crawler

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å¯åŠ¨æœåŠ¡
python main.py
```

### Dockeréƒ¨ç½²
```bash
# 1. æ„å»ºé•œåƒ
docker build -t lottery-python-crawler .

# 2. è¿è¡Œå®¹å™¨
docker run -d -p 8000:8000 --name lottery-python-crawler lottery-python-crawler
```

## ğŸ“¡ APIæ¥å£

### çˆ¬è™«ç®¡ç†
- `POST /crawl/start` - å¯åŠ¨æ•°æ®çˆ¬å–
- `GET /crawl/status` - è·å–çˆ¬å–çŠ¶æ€

### æ•°æ®åˆ†æ
- `GET /analysis/frequency/{lottery_type_id}` - é¢‘ç‡åˆ†æ
- `GET /analysis/hot_cold/{lottery_type_id}` - å†·çƒ­åˆ†æ
- `GET /analysis/sum_distribution/{lottery_type_id}` - å’Œå€¼åˆ†å¸ƒ

### é¢„æµ‹æ¨¡å‹
- `POST /prediction/generate` - ç”Ÿæˆé¢„æµ‹ç»“æœ
- `GET /prediction/models` - è·å–æ¨¡å‹åˆ—è¡¨
- `GET /prediction/evaluation/{model_id}` - æ¨¡å‹è¯„ä¼°

### å›¾è¡¨ç”Ÿæˆ
- `GET /charts/frequency/{lottery_type_id}` - é¢‘ç‡å›¾è¡¨
- `GET /charts/trend/{lottery_type_id}` - è¶‹åŠ¿å›¾è¡¨

## âš™ï¸ é…ç½®è¯´æ˜

### æ•°æ®åº“é…ç½®
```python
DATABASE_CONFIG = {
    'host': '192.168.1.34',
    'port': 3306,
    'user': 'lbc',
    'password': '19940314',
    'database': 'luck_money',
    'charset': 'utf8mb4'
}
```

### çˆ¬è™«é…ç½®
```python
CRAWLER_CONFIG = {
    'request_delay': 2,      # è¯·æ±‚é—´éš”(ç§’)
    'max_retries': 3,        # æœ€å¤§é‡è¯•æ¬¡æ•°
    'timeout': 30,           # è¯·æ±‚è¶…æ—¶(ç§’)
    'user_agent': '...'      # ç”¨æˆ·ä»£ç†
}
```

## ğŸ”§ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„å½©ç¥¨ç±»å‹
1. åœ¨`crawler.py`ä¸­æ·»åŠ çˆ¬å–æ–¹æ³•
2. åœ¨`data_analysis.py`ä¸­æ·»åŠ åˆ†æé€»è¾‘
3. åœ¨`prediction_models.py`ä¸­æ·»åŠ é¢„æµ‹æ¨¡å‹
4. æ›´æ–°APIæ¥å£

### è‡ªå®šä¹‰é¢„æµ‹æ¨¡å‹
1. ç»§æ‰¿`BasePredictionModel`ç±»
2. å®ç°`predict`æ–¹æ³•
3. åœ¨`PredictionModelFactory`ä¸­æ³¨å†Œ
4. æ·»åŠ æ¨¡å‹è¯„ä¼°é€»è¾‘

### æ•°æ®æºæ‰©å±•
1. åœ¨`DATA_SOURCES`ä¸­æ·»åŠ æ–°æº
2. å®ç°å¯¹åº”çš„è§£æå™¨
3. æ·»åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

## ğŸ“Š åŠŸèƒ½ç‰¹æ€§

### æ•°æ®çˆ¬å–
- å¤šå½©ç¥¨ç±»å‹æ”¯æŒ(å¤§ä¹é€ã€ç¦å½©3Dã€åŒè‰²çƒ)
- æ™ºèƒ½é‡è¯•å’Œé”™è¯¯å¤„ç†
- è¯·æ±‚é¢‘ç‡æ§åˆ¶
- æ•°æ®éªŒè¯å’Œæ¸…æ´—

### æ•°æ®åˆ†æ
- é¢‘ç‡ç»Ÿè®¡åˆ†æ
- å†·çƒ­å·ç åˆ†æ
- å’Œå€¼åˆ†å¸ƒåˆ†æ
- é—æ¼å€¼åˆ†æ

### é¢„æµ‹æ¨¡å‹
- é¢‘ç‡åˆ†ææ¨¡å‹
- é©¬å°”å¯å¤«é“¾æ¨¡å‹
- ç¥ç»ç½‘ç»œæ¨¡å‹
- æ—¶é—´åºåˆ—æ¨¡å‹

### å¯è§†åŒ–
- é¢‘ç‡åˆ†å¸ƒå›¾
- è¶‹åŠ¿åˆ†æå›¾
- çƒ­åŠ›å›¾
- äº¤äº’å¼å›¾è¡¨

## ğŸš€ éƒ¨ç½²è¯´æ˜

### ç”Ÿäº§ç¯å¢ƒ
1. ä½¿ç”¨Gunicorn + Uvicorn
2. é…ç½®Nginxåå‘ä»£ç†
3. è®¾ç½®æ—¥å¿—è½®è½¬
4. é…ç½®ç›‘æ§å‘Šè­¦

### æ€§èƒ½ä¼˜åŒ–
- å¼‚æ­¥çˆ¬å–
- è¿æ¥æ± ç®¡ç†
- ç¼“å­˜ç­–ç•¥
- ä»»åŠ¡é˜Ÿåˆ—

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-XX)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- åŸºç¡€çˆ¬è™«åŠŸèƒ½
- æ•°æ®åˆ†ææ¨¡å—
- é¢„æµ‹æ¨¡å‹æ¡†æ¶
- FastAPIæ¥å£
- Dockeræ”¯æŒ

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **æ•°æ®åº“è¿æ¥å¤±è´¥**: æ£€æŸ¥ç½‘ç»œå’Œè®¤è¯ä¿¡æ¯
2. **çˆ¬å–å¤±è´¥**: æ£€æŸ¥ç›®æ ‡ç½‘ç«™å¯è®¿é—®æ€§
3. **å†…å­˜ä¸è¶³**: è°ƒæ•´æ‰¹å¤„ç†å¤§å°
4. **ä¾èµ–å†²çª**: ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

### æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f logs/crawler.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep ERROR logs/crawler.log
```
